{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6BC-PgFgDy",
        "outputId": "1199e941-f58c-4f8d-97bd-dbfeadde3335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame carregado com sucesso!\n",
            "   customerID Churn                                           customer  \\\n",
            "0  0002-ORFBO    No  {'gender': 'Female', 'SeniorCitizen': 0, 'Part...   \n",
            "1  0003-MKNFE    No  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
            "2  0004-TLHLJ   Yes  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
            "3  0011-IGKFF   Yes  {'gender': 'Male', 'SeniorCitizen': 1, 'Partne...   \n",
            "4  0013-EXCHZ   Yes  {'gender': 'Female', 'SeniorCitizen': 1, 'Part...   \n",
            "\n",
            "                                             phone  \\\n",
            "0   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
            "1  {'PhoneService': 'Yes', 'MultipleLines': 'Yes'}   \n",
            "2   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
            "3   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
            "4   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
            "\n",
            "                                            internet  \\\n",
            "0  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
            "1  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
            "2  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
            "3  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
            "4  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
            "\n",
            "                                             account  \n",
            "0  {'Contract': 'One year', 'PaperlessBilling': '...  \n",
            "1  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
            "2  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
            "3  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
            "4  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# URL da fonte de dados\n",
        "url = \"https://raw.githubusercontent.com/alura-cursos/challenge2-data-science/refs/heads/main/TelecomX_Data.json\"\n",
        "\n",
        "# Faz a requisição HTTP para obter os dados\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "\n",
        "# Converte os dados para um DataFrame do Pandas\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostra as primeiras 5 linhas do DataFrame para verificar se o carregamento foi bem-sucedido\n",
        "print(\"DataFrame carregado com sucesso!\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe informações sobre o DataFrame, incluindo tipos de dados e valores não nulos\n",
        "print(\"\\nInformações sobre o DataFrame:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckjcNPx8FrZY",
        "outputId": "d33c5b82-4e31-44d1-8641-02d1f8bd6dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informações sobre o DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7267 entries, 0 to 7266\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   customerID  7267 non-null   object\n",
            " 1   Churn       7267 non-null   object\n",
            " 2   customer    7267 non-null   object\n",
            " 3   phone       7267 non-null   object\n",
            " 4   internet    7267 non-null   object\n",
            " 5   account     7267 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 340.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nColunas do DataFrame:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3loWFTzFuPF",
        "outputId": "06c12106-f293-4a9b-cae4-904c67166b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Colunas do DataFrame:\n",
            "Index(['customerID', 'Churn', 'customer', 'phone', 'internet', 'account'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica a quantidade de valores ausentes por coluna\n",
        "print(\"\\nValores ausentes por coluna:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Verifica a quantidade de linhas duplicadas\n",
        "print(\"\\nLinhas duplicadas:\")\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Analisa a coluna 'Cancelamento' para verificar inconsistências\n",
        "print(\"\\nValores únicos na coluna 'Cancelamento':\")\n",
        "print(df['Cancelamento'].unique())\n",
        "\n",
        "# Analisa a coluna 'TotalMensal'\n",
        "print(\"\\nValores na coluna 'TotalMensal' (os 50 primeiros):\")\n",
        "print(df['TotalMensal'].head(50))\n",
        "print(\"\\nVerificando se há valores inconsistentes na coluna 'TotalMensal':\")\n",
        "print(df['TotalMensal'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "AFU5mDwiFwG6",
        "outputId": "941c1dc4-4a73-41d5-be41-d7e295d3a1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valores ausentes por coluna:\n",
            "customerID          0\n",
            "Churn               0\n",
            "gender              0\n",
            "SeniorCitizen       0\n",
            "Partner             0\n",
            "Dependents          0\n",
            "tenure              0\n",
            "PhoneService        0\n",
            "MultipleLines       0\n",
            "InternetService     0\n",
            "OnlineSecurity      0\n",
            "OnlineBackup        0\n",
            "DeviceProtection    0\n",
            "TechSupport         0\n",
            "StreamingTV         0\n",
            "StreamingMovies     0\n",
            "Contract            0\n",
            "PaperlessBilling    0\n",
            "PaymentMethod       0\n",
            "Charges             0\n",
            "dtype: int64\n",
            "\n",
            "Linhas duplicadas:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'dict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1686769912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Verifica a quantidade de linhas duplicadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLinhas duplicadas:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Analisa a coluna 'Cancelamento' para verificar inconsistências\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6956\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6957\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6958\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6960\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   6924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6926\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6927\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         codes, uniques = factorize_array(\n\u001b[0m\u001b[1;32m    796\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_na_sentinel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitui os valores de string vazia por NaN\n",
        "df['TotalMensal'] = df['TotalMensal'].replace(' ', pd.NA)\n",
        "\n",
        "# Converte a coluna 'TotalMensal' para tipo numérico\n",
        "df['TotalMensal'] = pd.to_numeric(df['TotalMensal'])\n",
        "\n",
        "# Preenche os valores ausentes com 0\n",
        "df['TotalMensal'] = df['TotalMensal'].fillna(0)\n",
        "\n",
        "# Verificando a correção\n",
        "print(\"\\nTipo da coluna 'TotalMensal' após a correção:\")\n",
        "print(df['TotalMensal'].dtype)\n",
        "\n",
        "# Verificando se ainda existem valores nulos\n",
        "print(\"\\nValores nulos após a correção:\")\n",
        "print(df['TotalMensal'].isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "Tei7Rw1qFx7w",
        "outputId": "e0ba55ff-a641-40e6-830f-a2e3bc206f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'TotalMensal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TotalMensal'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-206387271.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Substitui os valores de string vazia por NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalMensal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalMensal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Converte a coluna 'TotalMensal' para tipo numérico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalMensal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalMensal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TotalMensal'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a nova coluna 'Contas_Diarias'\n",
        "df['Contas_Diarias'] = df['TotalMensal'] / 30\n",
        "\n",
        "# Exibe as 5 primeiras linhas com a nova coluna para verificar o resultado\n",
        "print(\"\\nDataFrame com a nova coluna 'Contas_Diarias':\")\n",
        "print(df[['TotalMensal', 'Contas_Diarias']].head())"
      ],
      "metadata": {
        "id": "eW2B2YVfGyCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca numpy, se ainda não estiver importada\n",
        "import numpy as np\n",
        "\n",
        "# Realiza a análise descritiva para as colunas numéricas\n",
        "# Usamos o método .describe() que já calcula várias métricas\n",
        "print(\"Análise Descritiva das Variáveis Numéricas:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "0bK8LLSfG7Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configura o estilo dos gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Conta a quantidade de clientes que cancelaram e os que não\n",
        "churn_counts = df['Cancelamento'].value_counts()\n",
        "\n",
        "# Calcula a porcentagem\n",
        "churn_proportions = df['Cancelamento'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Cria o gráfico de barras\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='Cancelamento', palette='viridis')\n",
        "plt.title('Distribuição da Evasão de Clientes (Churn)')\n",
        "plt.xlabel('Cancelamento (Sim/Não)')\n",
        "plt.ylabel('Número de Clientes')\n",
        "plt.xticks(ticks=[0, 1], labels=['Não', 'Sim'])\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nProporção de Clientes que Cancelaram:\")\n",
        "print(churn_proportions)"
      ],
      "metadata": {
        "id": "lVD_cR_UG70t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando a evasão por tipo de contrato\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Contrato', hue='Cancelamento', palette='viridis')\n",
        "plt.title('Evasão por Tipo de Contrato')\n",
        "plt.xlabel('Tipo de Contrato')\n",
        "plt.ylabel('Número de Clientes')\n",
        "plt.show()\n",
        "\n",
        "# Analisando a evasão por método de pagamento\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df, x='MetodoPagamento', hue='Cancelamento', palette='viridis')\n",
        "plt.title('Evasão por Método de Pagamento')\n",
        "plt.xlabel('Método de Pagamento')\n",
        "plt.ylabel('Número de Clientes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Analisando a evasão por serviço online (Internet)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='ServicoOnline', hue='Cancelamento', palette='viridis')\n",
        "plt.title('Evasão por Serviço Online')\n",
        "plt.xlabel('Serviço Online')\n",
        "plt.ylabel('Número de Clientes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVgY1A8bHB-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte as colunas para o tipo numérico, se necessário\n",
        "df['TempoDeContrato'] = pd.to_numeric(df['TempoDeContrato'], errors='coerce')\n",
        "df['TotalGasto'] = pd.to_numeric(df['TotalGasto'], errors='coerce')\n",
        "\n",
        "# Preenche os valores ausentes\n",
        "df['TempoDeContrato'].fillna(0, inplace=True)\n",
        "df['TotalGasto'].fillna(0, inplace=True)\n",
        "\n",
        "# Gráfico da distribuição do tempo de contrato por cancelamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Cancelamento', y='TempoDeContrato', data=df, palette='viridis')\n",
        "plt.title('Distribuição do Tempo de Contrato por Evasão')\n",
        "plt.xlabel('Cancelamento (Sim/Não)')\n",
        "plt.ylabel('Tempo de Contrato (meses)')\n",
        "plt.xticks(ticks=[0, 1], labels=['Não', 'Sim'])\n",
        "plt.show()\n",
        "\n",
        "# Gráfico da distribuição do total gasto por cancelamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Cancelamento', y='TotalGasto', data=df, palette='viridis')\n",
        "plt.title('Distribuição do Total Gasto por Evasão')\n",
        "plt.xlabel('Cancelamento (Sim/Não)')\n",
        "plt.ylabel('Total Gasto ($)')\n",
        "plt.xticks(ticks=[0, 1], labels=['Não', 'Sim'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IcmlG5_yHD-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de colunas a serem removidas\n",
        "colunas_para_remover = ['customerID']\n",
        "\n",
        "# Remove as colunas do DataFrame\n",
        "df = df.drop(columns=colunas_para_remover)\n",
        "\n",
        "print(f\"A coluna {colunas_para_remover} foi removida com sucesso.\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "aCWhCcz9H0F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifica as colunas categóricas\n",
        "colunas_categoricas = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "\n",
        "# Remove a coluna 'Churn' da lista, pois ela é o nosso alvo (target)\n",
        "colunas_categoricas.remove('Churn')\n",
        "\n",
        "# Aplica o One-Hot Encoding nas colunas categóricas\n",
        "df = pd.get_dummies(df, columns=colunas_categoricas, drop_first=True)\n",
        "\n",
        "# O get_dummies irá criar novas colunas.\n",
        "# Por exemplo, a coluna 'Contract' com valores 'Month-to-month' e 'Two year'\n",
        "# será convertida em 'Contract_Two year'.\n",
        "# A coluna 'Churn' (sim/nao) também precisa ser convertida\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "\n",
        "print(\"\\nDataFrame após a aplicação do One-Hot Encoding:\")\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "2xKXpee7C9nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a proporção de cada classe na coluna 'Churn'\n",
        "proporcao_churn = df['Churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Proporção de Clientes por Churn:\")\n",
        "print(proporcao_churn)\n",
        "\n",
        "# Visualiza o desequilíbrio com um gráfico de barras\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.countplot(x='Churn', data=df, palette='pastel')\n",
        "plt.title('Distribuição da Variável Churn')\n",
        "plt.xlabel('Churn (0 = Não, 1 = Sim)')\n",
        "plt.ylabel('Número de Clientes')\n",
        "plt.show()\n",
        "\n",
        "# Conclusão sobre o desequilíbrio\n",
        "if proporcao_churn[1] / proporcao_churn[0] < 0.5:\n",
        "    print(\"\\nAVISO: As classes da variável 'Churn' estão desbalanceadas. Considere aplicar técnicas de balanceamento.\")\n",
        "else:\n",
        "    print(\"\\nAs classes da variável 'Churn' estão relativamente balanceadas.\")"
      ],
      "metadata": {
        "id": "4rqsLYz4C_i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Separa as features (X) e a variável alvo (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "print(f\"Distribuição da classe antes do SMOTE: {Counter(y)}\")\n",
        "\n",
        "# Aplica SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(f\"Distribuição da classe após o SMOTE: {Counter(y_resampled)}\")\n",
        "\n",
        "# Opcional: Você pode converter os dados de volta para um DataFrame se precisar visualizá-los\n",
        "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Churn')], axis=1)\n",
        "\n",
        "print(\"\\nDataFrame com classes balanceadas criado (df_resampled).\")"
      ],
      "metadata": {
        "id": "wSV8YcgMDBel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identifica as colunas numéricas que serão padronizadas\n",
        "# Excluímos as colunas binárias que foram criadas no One-Hot Encoding\n",
        "colunas_numericas = ['TempoDeContrato', 'TotalMensal', 'Contas_Diarias']\n",
        "\n",
        "# Padroniza apenas as colunas numéricas\n",
        "scaler = StandardScaler()\n",
        "df_padronizado = df.copy()\n",
        "df_padronizado[colunas_numericas] = scaler.fit_transform(df_padronizado[colunas_numericas])\n",
        "\n",
        "print(\"\\nDataFrame após a padronização das colunas numéricas:\")\n",
        "print(df_padronizado.head())"
      ],
      "metadata": {
        "id": "LLlDE_hnDDOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calcula a matriz de correlação do DataFrame\n",
        "# O método .corr() calcula a correlação de Pearson por padrão\n",
        "correlacao = df.corr()\n",
        "\n",
        "# Define o tamanho da figura para melhor visualização\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Cria o heatmap\n",
        "sns.heatmap(correlacao, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "\n",
        "# Adiciona um título ao gráfico\n",
        "plt.title('Matriz de Correlação das Variáveis', fontsize=18)\n",
        "\n",
        "# Exibe o gráfico\n",
        "plt.show()\n",
        "\n",
        "# Opcional: Filtra a correlação com a variável 'Churn' para uma análise mais direta\n",
        "correlacao_com_churn = correlacao['Churn'].sort_values(ascending=False)\n",
        "print(\"\\nCorrelação das variáveis com a evasão (Churn):\")\n",
        "print(correlacao_com_churn)"
      ],
      "metadata": {
        "id": "r9eB9wBSDFr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gráfico para 'Tempo de Contrato' vs. 'Evasão'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Churn', y='TempoDeContrato', data=df, palette='viridis')\n",
        "plt.title('Distribuição de \"Tempo de Contrato\" por Evasão', fontsize=16)\n",
        "plt.xlabel('Evasão (0: Não, 1: Sim)', fontsize=12)\n",
        "plt.ylabel('Tempo de Contrato (meses)', fontsize=12)\n",
        "plt.xticks([0, 1], ['Não Evadiu', 'Evadiu'])\n",
        "plt.show()\n",
        "\n",
        "# Gráfico para 'Total Gasto' vs. 'Evasão'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Churn', y='TotalGasto', data=df, palette='viridis')\n",
        "plt.title('Distribuição de \"Total Gasto\" por Evasão', fontsize=16)\n",
        "plt.xlabel('Evasão (0: Não, 1: Sim)', fontsize=12)\n",
        "plt.ylabel('Total Gasto ($)', fontsize=12)\n",
        "plt.xticks([0, 1], ['Não Evadiu', 'Evadiu'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5YIFUDotDKbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separa as features (X) e o alvo (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Divide os dados em treino e teste (80/20)\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_treino.shape[0]} amostras\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_teste.shape[0]} amostras\")"
      ],
      "metadata": {
        "id": "mMIMUD7iDMIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalização dos dados de treino e teste para Regressão Logística\n",
        "scaler = StandardScaler()\n",
        "X_treino_normalizado = scaler.fit_transform(X_treino)\n",
        "X_teste_normalizado = scaler.transform(X_teste)\n",
        "\n",
        "# Cria e treina o modelo de Regressão Logística\n",
        "modelo_logistica = LogisticRegression(random_state=42, max_iter=1000)\n",
        "modelo_logistica.fit(X_treino_normalizado, y_treino)\n",
        "\n",
        "# Realiza previsões\n",
        "y_pred_logistica = modelo_logistica.predict(X_teste_normalizado)"
      ],
      "metadata": {
        "id": "wScnMUhdDOaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Cria e treina o modelo Random Forest\n",
        "modelo_random_forest = RandomForestClassifier(random_state=42)\n",
        "modelo_random_forest.fit(X_treino, y_treino)\n",
        "\n",
        "# Realiza previsões\n",
        "y_pred_random_forest = modelo_random_forest.predict(X_teste)"
      ],
      "metadata": {
        "id": "atBAMS-jDQO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def avaliar_modelo(y_true, y_pred, nome_modelo):\n",
        "    \"\"\"Calcula e imprime as métricas de avaliação do modelo.\"\"\"\n",
        "    acuracia = accuracy_score(y_true, y_pred)\n",
        "    precisao = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    matriz = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"--- Avaliação do Modelo: {nome_modelo} ---\")\n",
        "    print(f\"Acurácia: {acuracia:.4f}\")\n",
        "    print(f\"Precisão: {precisao:.4f}\")\n",
        "    print(f\"Recall:   {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(matriz)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Avalia a Regressão Logística\n",
        "avaliar_modelo(y_teste, y_pred_logistica, \"Regressão Logística\")\n",
        "\n",
        "# Avalia o Random Forest\n",
        "avaliar_modelo(y_teste, y_pred_random_forest, \"Random Forest\")"
      ],
      "metadata": {
        "id": "0pwf4vapDR_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise Crítica:\n",
        "\n",
        "Acurácia: Mede a proporção de previsões corretas.\n",
        "\n",
        "Precisão: Das previsões de \"churn\", quantas estavam corretas? Importante para evitar classificar um cliente como evasor quando ele não é.\n",
        "\n",
        "Recall: De todos os clientes que de fato evadiram, quantos o modelo conseguiu identificar? É crucial para a nossa análise, pois queremos identificar a maioria dos clientes que vão sair.\n",
        "\n",
        "F1-score: É a média harmônica da precisão e do recall. Útil quando há um desequilíbrio entre as classes."
      ],
      "metadata": {
        "id": "HwqMWjpJDW_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um DataFrame para visualizar os coeficientes\n",
        "importancia_logistica = pd.DataFrame(\n",
        "    {'variável': X.columns, 'coeficiente': modelo_logistica.coef_[0]}\n",
        ").sort_values(by='coeficiente', ascending=False)\n",
        "\n",
        "print(\"Variáveis mais importantes (Regressão Logística):\")\n",
        "print(importancia_logistica)"
      ],
      "metadata": {
        "id": "1KBKqAU6DelD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um DataFrame para visualizar a importância das variáveis\n",
        "importancia_rf = pd.DataFrame(\n",
        "    {'variável': X.columns, 'importancia': modelo_random_forest.feature_importances_}\n",
        ").sort_values(by='importancia', ascending=False)\n",
        "\n",
        "print(\"\\nVariáveis mais importantes (Random Forest):\")\n",
        "print(importancia_rf)"
      ],
      "metadata": {
        "id": "2ghw9EmoDjzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relatório de Modelagem Preditiva e Fatores de Evasão\n",
        "\n",
        "\n",
        "1. Introdução\n",
        "Este relatório detalha a construção e avaliação de modelos preditivos para identificar os principais fatores de evasão de clientes (churn) na TelecomX. O objetivo é fornecer insights acionáveis para a tomada de decisões estratégicas.\n",
        "\n",
        "2. Metodologia\n",
        "Pré-processamento: As variáveis categóricas foram transformadas usando One-Hot Encoding e as variáveis numéricas foram normalizadas para o modelo de Regressão Logística.\n",
        "\n",
        "Modelos: Foram utilizados dois modelos distintos: Regressão Logística e Random Forest. A Regressão Logística serve como um bom ponto de partida, enquanto o Random Forest, um modelo mais complexo, foi escolhido por sua robustez e capacidade de identificar relações não-lineares.\n",
        "\n",
        "Avaliação: O desempenho dos modelos foi avaliado usando Acurácia, Precisão, Recall, F1-score e a Matriz de Confusão.\n",
        "\n",
        "3. Resultados e Análise\n",
        "Desempenho dos Modelos:\n",
        "\n",
        "Regressão Logística:\n",
        "\n",
        "Acurácia: 0.7963\n",
        "\n",
        "F1-score: 0.6558\n",
        "\n",
        "Random Forest:\n",
        "\n",
        "Acurácia: 0.7997\n",
        "\n",
        "F1-score: 0.6384\n",
        "\n",
        "Ambos os modelos apresentaram um desempenho similar em termos de acurácia, com o Random Forest levemente superior. No entanto, o F1-score da Regressão Logística foi um pouco melhor. O F1-score é uma métrica mais balanceada para avaliar modelos em bases desequilibradas, como a nossa. Isso sugere que a Regressão Logística teve um desempenho um pouco melhor na identificação dos clientes que realmente evadiram, mesmo que sua acurácia geral seja marginalmente menor.\n",
        "\n",
        "Principais Fatores de Evasão:\n",
        "A análise de importância de variáveis de ambos os modelos consistentemente destacou os seguintes fatores como os mais relevantes para a previsão de evasão:\n",
        "\n",
        "Contrato Mensal (Contract_Month-to-month): Este foi um dos maiores preditores de churn, com um forte coeficiente positivo.\n",
        "\n",
        "Tempo de Contrato (TempoDeContrato): Clientes com menor tempo de contrato têm uma probabilidade significativamente maior de evadir.\n",
        "\n",
        "Cheque Eletrônico (MetodoPagamento_Electronic check): A utilização deste método de pagamento também está fortemente associada à evasão.\n",
        "\n",
        "Serviços Online (ServicoOnline_No internet service): A falta de serviço online parece influenciar a decisão de cancelamento.\n",
        "\n",
        "4. Estratégias de Retenção Baseadas em Dados\n",
        "Com base nos resultados, as seguintes ações podem ser implementadas para reduzir a evasão:\n",
        "\n",
        "Incentivos para Contratos Anuais: Criar campanhas agressivas com descontos ou benefícios exclusivos para clientes que migrarem de contratos mensais para anuais ou bianuais.\n",
        "\n",
        "Foco na Experiência do Cliente Novo: Oferecer um programa de acompanhamento proativo nos primeiros seis meses de serviço para garantir a satisfação e resolver problemas rapidamente.\n",
        "\n",
        "Otimização do Método de Pagamento: Avaliar a experiência do usuário com o cheque eletrônico e explorar alternativas que possam ser mais seguras e convenientes.\n",
        "\n",
        "Serviços Complementares: Analisar a oferta de serviços online para os clientes que optam por não tê-los. Entender se o motivo é a falta de necessidade, ou se há algo em sua oferta que não os atrai."
      ],
      "metadata": {
        "id": "glSjqyQuEFac"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HsJmfHLbEMJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}